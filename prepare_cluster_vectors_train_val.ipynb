{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare cluster vectors, can use ground truth instance annotations from coco dataset for training and validations sets. Need to use detector for test set. Test set cluster vectors prepared by using tf object detection api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/luoyy/datasets_large/mscoco/coco/'\n",
    "ANNOTATIONS = os.path.join(DATASET_PATH, 'annotations/')\n",
    "VAL_ANN = os.path.join(ANNOTATIONS, 'instances_val2014.json')\n",
    "TRAIN_VAL = os.path.join(ANNOTATIONS, 'instances_train2014.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# image_id: file_name mapping\n",
    "def imid_fn(image_dict):\n",
    "    \"\"\"\n",
    "        image_dict: json['images'], from annotations json\n",
    "    \"\"\"\n",
    "    imid_fn = {}\n",
    "    for img  in image_dict:\n",
    "        imid = img['id']\n",
    "        ifn = img['file_name']\n",
    "        imid_fn[imid] = ifn\n",
    "    return imid_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def cat_vector(ann_dict, imid_fn):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        ann_dict: j['annotations']\n",
    "        imid_fn : map from imid to filename\n",
    "    Returns vector, consisting of objects, represented on image\n",
    "    \"\"\"\n",
    "    cv_dict = defaultdict(list)\n",
    "    for ann in ann_dict:\n",
    "        ann_imid = ann['image_id']\n",
    "        f_name = imid_fn[ann_imid]\n",
    "        cat_id = ann['category_id']\n",
    "        if cat_id not in cv_dict[f_name]:\n",
    "            cv_dict[f_name].append(cat_id)\n",
    "    return cv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster_vector(cat_vn, class_num):\n",
    "    \"\"\"\n",
    "    Prepare cluster vector, labels must some to one\n",
    "        cat_v: dict {fn: [labels]}\n",
    "        class_num: number of classes (90 for mscoco)\n",
    "    \"\"\"\n",
    "    cv_dict = {}\n",
    "    for key in cat_vn:\n",
    "        zv = np.zeros(class_num + 1)\n",
    "        labels = cat_vn[key]\n",
    "        zv[labels] = 1\n",
    "        c_v = zv / zv.sum()\n",
    "        cv_dict[key] = c_v\n",
    "    return cv_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read json annotation files\n",
    "with open(TRAIN_VAL) as rf:\n",
    "    train = json.load(rf)\n",
    "\n",
    "with open(VAL_ANN) as rf:\n",
    "    val = json.load(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['info', 'images', 'licenses', 'annotations', 'categories'])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mscoco unused ids in range 0-90(inclusive)\n",
    "range_max = set(range(91))\n",
    "cats = set()\n",
    "for entry in train['categories']:\n",
    "    cats.add(entry['id'])\n",
    "unused_cats = range_max.difference(cats)\n",
    "print(unused_cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training cluster vector\n",
    "train_ifn = imid_fn(train['images'])\n",
    "train_cv = cat_vector(train['annotations'], train_ifn)\n",
    "train_cv = cluster_vector(train_cv, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# validation cluster vector\n",
    "val_ifn = imid_fn(val['images'])\n",
    "val_cv = cat_vector(val['annotations'], val_ifn)\n",
    "val_cv = cluster_vector(val_cv, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82081\n",
      "40137\n"
     ]
    }
   ],
   "source": [
    "# test, see, that dicts dont include all images from caption set\n",
    "print(len(list(train_cv.keys())))\n",
    "print(len(list(val_cv.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# concateate 2 dictionaries, more convenient\n",
    "c_v = dict(train_cv, **val_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serialize\n",
    "if not os.path.exists('./obj_vectors'):\n",
    "    os.makedirs('./obj_vectors')\n",
    "with open('./obj_vectors/c_v.pickle', 'wb') as wf:\n",
    "    pickle.dump(c_v, wf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
